{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k13WcJbG3szS"
      },
      "source": [
        "# [NML24] Assignment 3: Graph Generation\n",
        "\n",
        "TAs: [Manuel Madeira](https://people.epfl.ch/manuel.madeira) and [Yiming Qin](https://people.epfl.ch/yiming.qin)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WzsnXWZ3yRM"
      },
      "source": [
        "## Students\n",
        "\n",
        "* Team: 5\n",
        "* Students: Hans Kristian Bjorgo Kvaerum (381875), Kaede Johnson (357472)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa5x0u-A3FJp"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "> ⚠️ **Read carefully before starting**\n",
        "\n",
        "**Deadline:** May 28\n",
        "\n",
        "**Grading:**\n",
        "* The integrality of Assignment 1 will be scaled to 100% and will amount to 1/3 of the overall assignments score.\n",
        "* The total number of points is **60**, the points for each exercise are stated in the instructions.\n",
        "* All team members will receive the same grade based on the team solution.\n",
        "* Collaboration between team members is encouraged. No collaboration between teams is allowed.\n",
        "\n",
        "\n",
        "**Expected output:**\n",
        "\n",
        "You will have coding and theoretical questions. Coding exercises shall be solved within the specified space:\n",
        "```python\n",
        "# Your solution here ###########################################################\n",
        "...\n",
        "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "```\n",
        "Sometimes we provide variable names, such as `x = ...`; do not change names and stick to hinted typing, as they will be reused later.\n",
        "Within the solution space, you can declare any other variable of function that you might need, but anything outside these lines shall not be changed, or it will invalidate your answers.\n",
        "\n",
        "Theoretical questions shall be answered in the following markdown cell. The first line will be\n",
        "```markdown\n",
        "**Your answer here:**\n",
        "...\n",
        "```\n",
        "\n",
        "**Solutions:**\n",
        "* Your submission is self-contained in the `.ipynb` file.\n",
        "\n",
        "* Code has to be clean and readable. Provide meaningful variable names and comment where needed.\n",
        "\n",
        "* Textual answers in [markdown cells][md_cells] shall be short: one to two\n",
        "  sentences. Math shall be written in [LaTeX][md_latex].\n",
        "    **NOTE**: handwritten notes pasted in the notebook are ignored\n",
        "\n",
        "* You cannot import any other library than we imported, unless explicitly stated.\n",
        "\n",
        "* Make sure all cells are executed before submitting. I.e., if you open the notebook again it should show numerical results and plots. Cells not run are ignored.\n",
        "\n",
        "* Execute your notebook from a blank state before submission, to make sure it is reproducible. You can click \"Kernel\" then \"Restart Kernel and Run All Cells\" in Jupyter. We might re-run cells to ensure that the code is working and corresponds to the results.\n",
        "\n",
        "[md_cells]: https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html\n",
        "[md_latex]: https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html#LaTex-equations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx42KF-743mu"
      },
      "source": [
        "## Objective\n",
        "\n",
        "Graph generative models enable the generation of synthetic graph data that mimic the characteristics of real-world graphs by approximating (implictly or explictly) their training graphs probability distribution. This is useful when real data is limited or sensitive, allowing researchers to perform simulations and experiments without privacy concerns or data scarcity issues, to detect anomalies or even to generate new unseen but plausible graphs that verify given properties. Drug discovery or protein design are two examples of real-world applications that can obviously benefit from further development of graph generative models.\n",
        "\n",
        "The purpose of this assignment is to explore different graph generation algorithms and understand their properties. In the first part, we will explore a non-deep learning approach: Erdős–Rényi model. In the second part, we will implement a deep learning approach based on discrete diffusion. Finally, we will explore how to compare the two generative models.\n",
        "\n",
        "**Notes:**\n",
        "\n",
        "- Throughout this assignment, we focus on undirected and unweighted graphs that do not contain self-loops. Nevertheless, we remark that the adopted methods could naturally be extended for those settings.\n",
        "\n",
        "- We encourage you to fill in the code by the order provided in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "khSYq9TLJOkf"
      },
      "outputs": [],
      "source": [
        "!pip install torch_geometric -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bjrSrleU86b-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Importing dependencies\n",
        "%matplotlib inline\n",
        "\n",
        "from typing import List, Dict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn import metrics\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import assignment3_utils as utils\n",
        "from placeholder import PlaceHolder, to_dense, er_validation_step\n",
        "\n",
        "\n",
        "# Set device\n",
        "utils.seed_everything(0)\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"  # cuda index to be changed\n",
        "print('current device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oss5HTlPI-ea"
      },
      "source": [
        "# Part 1: Erdős–Rényi model [15 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENeQB1RSI-ea"
      },
      "source": [
        "In this part, we explore the Erdős–Rényi model, which is a random graph model. As discussed in class, this model is defined by two parameters: the number of nodes $n$ and the probability $p$ of connecting any two nodes with an edge. The model generates a graph by connecting each pair of nodes with probability $p$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmXbOookI-ea"
      },
      "source": [
        "### Question 1.1: Generating Erdős–Rényi graphs [8 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVwEcAbsI-ea"
      },
      "source": [
        "**1.1.1. [3 points]** Implement the function `generate_ER_graph`, which takes as input the number of nodes $n$ and the probability of an edge between every two nodes $p_{\\text{ER}}$, and returns an Erdős–Rényi graph. This implementation should not use the `networkx` method `erdos_renyi_graph`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYYSdqKOI-ea"
      },
      "outputs": [],
      "source": [
        "def generate_ER_graph(n: int, p_er: float) -> nx.Graph:\n",
        "    # Your solution here ###########################################################\n",
        "\n",
        "    graph = ...\n",
        "\n",
        "    #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "    return graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0LCi9TbI-ea"
      },
      "source": [
        "We will now plot a graph with 50 nodes and edge probability $p_{\\text{ER}} = 0.2$ yielded by your method. We compare it to a graph coming from the `networkx` method `erdos_renyi_graph`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-C1FT6QI-ea"
      },
      "outputs": [],
      "source": [
        "n = 50\n",
        "p_er = 0.2\n",
        "\n",
        "g_student = generate_ER_graph(n, p_er)\n",
        "g_nx = nx.erdos_renyi_graph(n, p_er)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPE1DOsbI-ea"
      },
      "outputs": [],
      "source": [
        "def plot_nx_graph(nx_graph):\n",
        "    nx.draw(nx_graph)\n",
        "    plt.show()\n",
        "\n",
        "plot_nx_graph(generate_ER_graph(n, p_er))\n",
        "plot_nx_graph(nx.erdos_renyi_graph(n, p_er))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flc-O_GhI-ea"
      },
      "source": [
        "As you can notice, it is hard to have any meaningful comparison or statement over the generated graphs just based on visual inspection. To overcome this limitation, a typical approach is to compute some graph statistics and perform the comparison at that level. In the next question, we explore this idea by evaluating the number of edges of the generated graphs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1HyMxwTI-ea"
      },
      "source": [
        "**1.1.2. [2 points]** Derive the average and standard deviation of the number of edges of a Erdős–Rényi graph with $n$ nodes and $p$ probability of connection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0WATvH6I-ea"
      },
      "source": [
        "**Your answer here:**\n",
        "\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64PUIxuvI-ea"
      },
      "source": [
        "**1.1.3 [1 point]** **Inspect** the number of edges of the generated graphs and **compare** it with the expected number of edges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPMAF1z-I-ea"
      },
      "outputs": [],
      "source": [
        "# Your solution here ###########################################################\n",
        "edges_our = ...\n",
        "edges_nx = ...\n",
        "expected_edges = ...\n",
        "std_edges = ...\n",
        "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "print(f\"Expected edges: {expected_edges} ± {std_edges}\")\n",
        "print(f\"Number of edges in our graph: {edges_our}\")\n",
        "print(f\"Number of edges in nx graph: {edges_nx}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7VJ9nEzsmTE"
      },
      "source": [
        "**1.1.4 [2 points]** **Describe:** What do you observe? What can you conclude?\n",
        "\n",
        "**Hint:** Is the result statistically meaningful? Can you think of a more robust estimator to the expected number of edges?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILhH9rvhI-eb"
      },
      "source": [
        "**Your answer here:**\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj2GuawbI-eb"
      },
      "source": [
        "\n",
        "### Question 1.2: Learning a Erdős–Rényi graph from data [7 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwL5EcJEI-eb"
      },
      "source": [
        "As discussed in class, the main objective of graph generative models is to capture the underlying distribution of the graph data. This is typically done by assuming a parametric model for such distribution and then learning those parameters from the observed data. Such model, where the parameters are set to the estimated ones (i.e. a trained model), is then used to sample fresh new graphs. Depending on the suitability of the assumptions of the model and on its expressivity, the generated graphs may or may not be similar to the observed ones. Throughout this assignment, we will explore different generative models and compare their performance. We will store the set of generated graphs by the different methods in the variable `graphs_to_eval` for the final evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J114KktxI-eb"
      },
      "outputs": [],
      "source": [
        "graphs_to_eval = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kknIYm8fI-eb"
      },
      "source": [
        "In this question, we will explore how to learn a Erdős–Rényi graph from data. We start by loading the data. Note that the dataset has three splits: train, validation, and test. As usual, we will use the train split to learn the Erdős–Rényi model and evaluate the learned model on the test split. Since we will not need to do any hyperparameter tuning, we leave the validation split out for now.\n",
        "\n",
        "The dataset used in the assignment is composed of clear community structures, consisting of densely connected nodes within communities and sparser connections across them. Each graph in this dataset contains no more than 20 nodes and is limited to a maximum of 2 clusters.\n",
        "\n",
        "We now load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaN664XyI-eb"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"dataset.pt\"\n",
        "nx_dataset = utils.get_nx_dataset(dataset_path)\n",
        "\n",
        "print(f\"Number of graphs in the train set: {len(nx_dataset['train'])}\")\n",
        "print(f\"Number of graphs in the validation set: {len(nx_dataset['val'])}\")\n",
        "print(f\"Number of graphs in the test set: {len(nx_dataset['test'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r-JPSnPI-eb"
      },
      "source": [
        "As seen above, the ER model is parameterized by the number of nodes, $n$, and the probability of connection, $p$, so these are the parameters we must learn from the train dataset, $D$. In particular, we want to be able to sample $\\hat{n} \\, , \\,\\hat{p} \\,\\sim p(n, p)$, so that we can feed an ER model generator with such parameters to obtain a fresh new graph.\n",
        "\n",
        "But how to obtain $p(n, p)$?\n",
        "\n",
        "In the provided dataset, the number of nodes is not constant across graphs, so we can naturally model it as a categorical distribution based on the marginal probabilities of number of nodes observed in the dataset, which is equivalent to:\n",
        "\n",
        "$$\n",
        "p(n) = \\frac{\\sum_{G_i \\in D} \\mathbf{1}_{\\{\\text{number of nodes} (G_i)\\} = n\\}}}{|D|}\n",
        "$$\n",
        "\n",
        "\n",
        "For $p$, we will assume that it is constant, $\\hat{p}$ , and independent of $n$. Therefore, we get:  \n",
        "$$\n",
        "p(n, p) = p(n) \\hat{p} .\n",
        "$$\n",
        "\n",
        "So, under these modelling assumptions, we can now sample from the joint distribution $p(n, p)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in143Rj3I-eb"
      },
      "source": [
        "**1.2.1 [5 points]** **Implement** a function to learn the proposed categorical distribution over $n$, `estimate_n_cat_dist`. **Propose and implement** a function to estimate $\\hat{p}$, `estimate_p`, explaining your reasoning behind its design, and finally **implement** a function to sample from the learned model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNvUiVSbI-eb"
      },
      "outputs": [],
      "source": [
        "class ER_prob_model():\n",
        "    def __init__(self) -> None:\n",
        "        pass\n",
        "\n",
        "    def fit(self, dataset):\n",
        "        self.p = self.estimate_p(dataset)\n",
        "        self.n_dist = self.estimate_n_cat_dist(dataset)\n",
        "        print(f\"Estimated p: {self.p}\")\n",
        "        print(f\"Estimated n categorical distribution: {self.n_dist}\")\n",
        "\n",
        "    def estimate_n_cat_dist(self, dataset: List[nx.Graph]) -> Dict[int, float]:\n",
        "        \"\"\"Output must be a dictionary where keys are the number of nodes and values are the probability of that number of nodes.\"\"\"\n",
        "        # Your solution here ###########################################################\n",
        "        n_dist = ...\n",
        "        #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "        return n_dist\n",
        "\n",
        "    def estimate_p(self, dataset: List[nx.Graph]) -> float:\n",
        "        \"\"\"Output must be a single floating point number representing the probability of an edge existing between two nodes.\"\"\"\n",
        "        # Your solution here ###########################################################\n",
        "        p = ...\n",
        "        #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "        return p\n",
        "\n",
        "    def sample_ER_graphs(self, n_graphs: int) -> List[nx.Graph]:\n",
        "        \"\"\"Output must be a list of n_graphs ER graphs sampled from the model. Note that you should use the estimated parameters, self.n_dist and self.p (see `fit` function).\"\"\"\n",
        "        # Your solution here ###########################################################\n",
        "        graphs = ...\n",
        "        #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "        return graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqUVFyAGI-eb"
      },
      "source": [
        "Time to sample some fresh new graphs using your proposed model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXEBhkigI-eb"
      },
      "outputs": [],
      "source": [
        "train_dataset = nx_dataset[\"train\"]\n",
        "num_graphs_to_generate = len(nx_dataset[\"test\"])\n",
        "\n",
        "# Learn the parameters of the ER model using the training dataset\n",
        "er_model = ER_prob_model()\n",
        "er_model.fit(train_dataset)\n",
        "\n",
        "# Generate ER graphs using the learned model and visualizing the first 5\n",
        "graphs_to_eval[\"ER\"] = er_model.sample_ER_graphs(num_graphs_to_generate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhYsa-UII-eb"
      },
      "source": [
        "Let us plot the first two generated graphs with the learned model and compare them with the first two graphs of the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyZKc_CnI-eb"
      },
      "outputs": [],
      "source": [
        "print(\"Plotting generated graphs:\")\n",
        "for graph in graphs_to_eval[\"ER\"][:2]:\n",
        "    plot_nx_graph(graph)\n",
        "\n",
        "print(\"Plotting test graphs:\")\n",
        "for graph in nx_dataset[\"test\"][:2]:\n",
        "    plot_nx_graph(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGLvI7e6I-eb"
      },
      "source": [
        "**1.2.2 [2 points]** Based on the generated graphs above, do you think the Erdős–Rényi (ER) model able to model the correct graph distribution? Justify your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYDbWY1II-eb"
      },
      "source": [
        "**Your answer here:**\n",
        "\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs8WiG7qI-eb"
      },
      "source": [
        "Keep these plots in the back of your mind and let us proceed now to a more sophisticated approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFaSh9I-I-ec"
      },
      "source": [
        "# **Part 2: Graph Diffusion Models [30 pts]**\n",
        "\n",
        "Unlike random graph models, which rely on predetermined random distributions, deep models derive directly from data distributions and offer a robust framework for approximating any distribution by capturing complex data patterns effectively. In this section, we focus on leveraging Graph Neural Networks (GNNs) for graph generation.\n",
        "\n",
        "Among the deep learning strategies, we encounter graph-based Generative Adversarial Networks (Graph GANs), Variational Autoencoders (VAEs), and, more recently, Diffusion Models. Each method brings unique strengths, but Diffusion Models have emerged as particularly powerful due to their excellent performance and stable training processes. We will guide you through the implementation of a simplified version of a state-of-the-art discrete diffusion model, DiGress (*Vignac* et al., DiGress, ICLR 2023).\n",
        "\n",
        "For those of you that are familiar with the application of diffusion models to images - where we add (continuous) Gaussian noise to each pixel of an image until we achieve pure white noise, and then learn a model that can gradually recover the image from this white noise -, the intuition behind this graph diffusion model is quite similar! However, the key difference lies in the nature of the data: graphical data is often discrete, typically represented by a 0/1 adjacency matrix for general graph structures, and as categorical data for molecular graphs where each node (atom) and each edge (covalent bond) are categorized. In this setting, instead of Gaussian noise, we define a Markov Chain on the discrete space using transition matrices. If you are not familiar with Markov Chains, do not worry. In the upcoming implementation, you should be able to intuitively understand this method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QpmfgJ8I-ec"
      },
      "source": [
        "### Question 2.1 - Data Processing [5 points]\n",
        "\n",
        "In this part of the assignment, we will implement functions related to graphical data coming from the community-based dataset (named `nx_dataset`) obtained in Part 1 and compile some statistics that will be useful in subsequent sections.\n",
        "\n",
        "Since we are using unattributed graphs (i.e., graphs with no special node types or edge types), all we have to model is the existence/absence of edges between nodes (i.e., the adjacency matrix). Therefore, each edge belongs to one of two types: `existing` or `non-existing`.\n",
        "\n",
        "Diffusion models are commonly applied to data modalities with a constant number of variables, such as images, where height and width are fixed, consequently fixing the total number of pixels as well. However, graph datasets do not have a fixed number of nodes nor edges. To address this, we separate the tasks of modeling the number of nodes and the adjacency matrix. The generation process involves two steps:\n",
        "\n",
        "1. Sample the number of nodes for the graph to be generated.\n",
        "2. Generate the corresponding adjacency matrix, with the node count fixed from the first step.\n",
        "\n",
        "In the first step, we model the number of nodes using the distribution of number of nodes of the graphs in the training dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmu8XPAvI-ec"
      },
      "source": [
        "**2.1.1. [2 points]** **Write a function** that, given a dataset, returns the distribution of the number of nodes. We also include '0' nodes as a valid category in our model, ensuring that the returned array spans from zero to the maximum number of nodes plus one. Thus, the shape of the array will be (max_n_nodes + 1,)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_4taBilI-ec"
      },
      "outputs": [],
      "source": [
        "def count_n_node(dataset: List[nx.Graph]) -> np.ndarray:\n",
        "    \"\"\"Output must be a numpy array of shape (max_n_nodes + 1,) containing the probability of each number of nodes in the dataset, where max_n_nodes is the highest number of nodes found for a single graph in the dataset.\"\"\"\n",
        "    # Your solution here ###########################################################\n",
        "    prob = ...\n",
        "\n",
        "    #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "    return prob\n",
        "\n",
        "n_nodes_dist = torch.tensor(count_n_node(nx_dataset['train']))\n",
        "max_n_nodes = len(n_nodes_dist)-1\n",
        "print(f\"The maximum number of nodes is: {max_n_nodes}\")\n",
        "print(f\"The distribution of node numbers is: {n_nodes_dist}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T4403KfI-ed"
      },
      "source": [
        "<!-- #### Implementing PlaceHolders -->\n",
        "\n",
        "We now implement a class that will reveal itself quite helpful along the implementation of the diffusion model. This class, named `PlaceHolder`, will store the information regarding a batch of graphs in a flexible way. When containing a graph, it will store an edge tensor, $E$, a node tensor, $X$, and a graph-level tensor, $y$. $E$ will be a binary tensor of shape `(bs, n, n, 2)`, where `n` is the number of nodes in the graph, and `bs` is the batch-size. Accordingly, $X$ will be a tensor of shape `(bs, n, 1)`, and the graph-level tensor is a tensor of shape `(bs, 1)`. While it may seem strange at this point to store $X$ and $y$ while we are only interested in modelling the adjacency matrix, you will see that this implementation will become handy later.\n",
        "\n",
        "To better understand what a placeholder stores, we provide the following example:\n",
        "- **Probability distribution:** Let us focus on the entry $E[i,j,k,:] = [p_0, p_1]$, for any $0 \\leq i < bs$ and $0 \\leq j,k < n$. $p_0$ will be the probability of the edge between nodes $j$ and $k$ in the $i$-th graph of the batch being `non-existing`, while $p_1$ will be the probability of the edge between nodes $j$ and $k$ in the $i$-th graph of the batch being `existing`. Naturally, we must have $p_0 + p_1 = 1$.\n",
        "<!-- - **Realization:** Importantly, a realization of such probability distribution (edges sampled from such probability distribution) can also be represented as a placeholder. For the provided example, if we sample an edge from such distribution, we will have with probability $p_0$ an edge of type `non-existing`, $E[i,j,k,:] = [1, 0]$, and with probability $p_1$ an edge of type `existing`, $E[i,j,k,:] = [0, 1]$. -->\n",
        "- **Masking:** As graphs within the same batch may have different sizes, but batch operations require consistent dimensions (for efficient GPU execution), we need to mask out unnecessary parts of the tensors. For instance, if the batch size is 2, and the first graph has 10 nodes while the second has 20 nodes, then $X$ would be of size $(2, 20, 1)$, and $E$ would be of size $(2, 20, 20, 2)$. For the first graph, which only includes 10 nodes, we need to mask $X[0, 10:]$ as zero. Consequently, we need to proceed similary for the entries in $E[0, 10:, :]$ and $E[0, :, 10:]$, setting them to $[0, 0]$. Moreover, since we are considering graphs without self-loops, the diagonal of $E$ must also be masked to zero. This operation is implemented in `PlaceHolder.mask()`.\n",
        "\n",
        "These observations show that a placeholder can store both the probability distributions and as well as their realizations (as one-hot encodings), being more suitable for our objective than storing the graphs in the usual `torch_geometric.data.Data` objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkdCpoWPI-ed"
      },
      "source": [
        "**2.1.2. [3 points]** In the python file `placeholder.py`, **define `e_mask1` and `e_mask2`** with dimensions `(bs, n, 1, 1)` and `(bs, 1, n, 1)` respectively for masking edges in graphs of variable sizes, and **create `diag_mask`** of shape `(bs, n, n, 1)` to eliminate self-loops by masking diagonal entries. Please run the following block after you finished your function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0PSO5l-I-ed"
      },
      "outputs": [],
      "source": [
        "import placeholder\n",
        "import importlib\n",
        "importlib.reload(placeholder)\n",
        "from placeholder import PlaceHolder\n",
        "\n",
        "# Test masking\n",
        "bs = 2\n",
        "\n",
        "n_nodes = 4\n",
        "num_node_classes = 1\n",
        "num_edge_classes = 2\n",
        "graph_1_mask = torch.cat((torch.tensor([True] * 2), torch.tensor([False] * 2)), dim=0)\n",
        "graph_2_mask = torch.cat((torch.tensor([True] * 3), torch.tensor([False] * 1)), dim=0)\n",
        "node_mask = torch.vstack((graph_1_mask, graph_2_mask))\n",
        "holder = PlaceHolder(X=torch.ones(bs, n_nodes, num_node_classes), E=torch.ones(bs, n_nodes, n_nodes, num_edge_classes), y=None).mask(node_mask)\n",
        "\n",
        "print(node_mask.shape)\n",
        "print(holder)\n",
        "print(holder.X[0])\n",
        "print(holder.X[1])\n",
        "print(holder.E[0])\n",
        "print(holder.E[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnGinQERI-ed"
      },
      "source": [
        "### Question 2.2 - Discrete Diffusion Process [6 points]\n",
        "\n",
        "In this part, we will simulate a discrete diffusion process over $T=1000$ steps. Discrete diffusion involves gradually corrupting categorical data towards a random distribution. For example, a vector $[0,1,0,0]$ might evolve under noise to $[0.1,0.7,0.1,0.1]$ at step $t=200$, and eventually reach a uniform distribution like $[0.25, 0.25, 0.25, 0.25]$ at $t=T=1000$.\n",
        "\n",
        "The process utilizes a transition matrix $Q_t$ for each step $t$ in $[1,...,T]$, which is a square matrix of size $(k,k)$, where $k$ is the number of categories. The matrix $Q_t$  can be computed with $Q_t=\\alpha^t \\mathbb{I} + \\beta^t \\mathbf{1} \\mathbf{1}'/n$, where $\\mathbf{1}'$ is the transpose of the array $\\mathbf{1}$, fully filled with ones, of size $(n, 1)$. It combines two components:\n",
        "- An identity matrix $\\mathbb{I}$ scaled by $\\alpha^t$, preserving the original data distribution.\n",
        "- A matrix $\\mathbf{1} \\mathbf{1}'/k$ where all entries are $1/k$, scaled by $\\beta^t$, representing the noise based on a uniform distribution. Here, $\\beta^t$ increases from 0 to 1 as $t$ approaches $T$, with $\\alpha^t = 1 - \\beta^t$.\n",
        "\n",
        "The transition matrix $ Q_t $, defining transitions from step $ t $ to $ t+1 $, incrementally introduces noise at each step, perturbing the original distribution. In particular, the entry $Q_t[i, j]$ defines the probability of an edge (in this case, but it works for any other modelling variable laying in a discrete state-space) going from state $i$ at timestep $t$ to state $j$ at timestep $t+1$. This process is mathematically guaranteed to approach a uniform categorical distribution as $ T $ becomes large, where $T $ represents the total number of diffusion steps.\n",
        "\n",
        "The $\\beta^t$ values follow a predefined schedule, which is implemented in the following code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IxFofYtN-tk"
      },
      "source": [
        "We provide some introduction to the Markov chain here, in case you need.\n",
        "\n",
        "For a Markov chain with a finite state space, the transition probabilities can be represented in a square matrix $ P $ where each element $ P_{ij} $ of the matrix represents the probability of moving from state $ i $ to state $ j $ in one step. Mathematically, $ P_{ij} $ is defined as:\n",
        "$$ P_{ij} = \\Pr(X_{n+1} = j \\mid X_n = i) $$\n",
        "where $ X_n $ is the state at time $ n $. For the matrix $ P $ to be valid, each row must satisfy the following conditions:\n",
        "- $ 0 \\leq P_{ij} \\leq 1 $\n",
        "- $ \\sum_{j \\in S} P_{ij} = 1 $ for all $ i \\in S $"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRd75i9RI-ed"
      },
      "outputs": [],
      "source": [
        "T = 1000\n",
        "\n",
        "all_betas = utils.get_betas(timesteps=T, s=0.008)\n",
        "all_alphas = utils.get_alphas(timesteps=T)\n",
        "all_alphas_bar = utils.get_alphas_bar(all_alphas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcpYc_A3I-ed"
      },
      "source": [
        "In the code above, we compute not only $\\alpha_t$ but also $\\bar{\\alpha_t}^{bar}$, where $\\bar{\\alpha}^{bar}_t$ is the cumulative product of $\\alpha_t$ from step 0 to step $t$, defined as $\\bar{\\alpha}^{bar}_t = \\alpha_0 \\times \\alpha_1 \\times ... \\times \\alpha_t$.\n",
        "\n",
        "By using $\\bar{\\alpha}^{bar}$, we can directly compute the transition matrix from step 0 to step $t$ without the need of iteratively computing transitions from $0 \\to 1$, $1 \\to 2$, ..., $t-1 \\to t$. Specifically, the transition matrix from $0$ to $t$, denoted $\\bar{Q}^{bar}_t$, is calculated as $\\bar{\\alpha}^{bar}_t \\mathbb{I}+(1-\\bar{\\alpha}^{bar}_t)\\mathbf{1} \\mathbf{1}'/k$, where $\\mathbb{I}$ represents the identity matrix of size $(k,k)$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIy3iIUVI-ed"
      },
      "source": [
        "**2.2.1. [2 points]** Please **explicitly write the expression** (no coding for now) for $\\bar{Q}_t$ when $t=1$, $t=500$ and $t=1,000$ and **analyse the motivation of defining $\\bar{\\alpha}$** in this way intuitively. You may need to consult the variable `alphas_bar` defined above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxSOBUuuI-ed"
      },
      "source": [
        "**Your answer here:**\n",
        "\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b67A7B_JI-ed"
      },
      "source": [
        "**2.2.2. [4 points]** **Implement the computation** for $Q_t$ and $\\bar{Q}_t$ for edges according to the definition above.\n",
        "\n",
        "Hint: to make the implementation easier, you do not compute $\\mathbf{1}\\mathbf{1}'/k$ to create the noise matrix; instead, we define the noise distribution $\\mathbf{1}'/k$ (of size `(2)` denoted as noise_dist in the following function) then expand it's dimensions to reach the correct sizes (`bs, 2, 2`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2ytgfcYI-ed"
      },
      "outputs": [],
      "source": [
        "def get_Q_t(betas: torch.Tensor, noise_dist: torch.Tensor, e_class=2) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        - betas, (bs, )\n",
        "        - noise_dist, (e_class, 1) -> the noise distribution at step $t=1,000$, here we take by default (0.5, 0.5)\n",
        "        - e_class, number of classes for edges\n",
        "    Output:\n",
        "        - q_e, (bs, e_class, e_class)\n",
        "    \"\"\"\n",
        "    # Your solution here ###########################################################\n",
        "    q_e = ...\n",
        "    #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "    assert ((q_e.sum(dim=2) - 1.0).abs() < 1e-4).all()  # ensure each row of q_e represents a distribution\n",
        "    return q_e\n",
        "\n",
        "def get_Q_t_bar(alphas_bar: torch.Tensor, noise_dist: torch.Tensor, e_class: int =2) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        - alphas_bar, (bs, )\n",
        "        - noise_dist, (e_class, 1) -> the noise distribution at step $t=1,000$, here we take by default (0.5, 0.5)\n",
        "        - e_class, number of classes for edges\n",
        "    Output:\n",
        "        - q_e, (bs, e_class, e_class)\n",
        "    \"\"\"\n",
        "    # Your solution here ###########################################################\n",
        "    q_e = ...\n",
        "    #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "    assert ((q_e.sum(dim=2) - 1.0).abs() < 1e-4).all()  # ensure each row of q_e represents a distribution\n",
        "    return q_e\n",
        "\n",
        "\n",
        "# example for test\n",
        "noise_dist = torch.Tensor([0.5, 0.5])\n",
        "betas_t = utils.get_betas(1000)[:2]\n",
        "alphas_bar_t = utils.get_alphas_bar(utils.get_alphas(1000))[:2]\n",
        "Qt = get_Q_t(betas_t, noise_dist, e_class=2)\n",
        "Qt_bar = get_Q_t_bar(alphas_bar_t, noise_dist, e_class=2)\n",
        "\n",
        "print(f\"Qt: {Qt}, {Qt.shape}\")\n",
        "print(f\"Qt_bar: {Qt_bar}, {Qt_bar.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5wRHtuhI-ed"
      },
      "source": [
        "### Question 2.3 - Apply Noise to Data [5 points]\n",
        "\n",
        "Now that the components of discrete diffusion are completed, we can proceed to corrupt graphs!\n",
        "\n",
        "To achieve this, you will implement a function called `apply_noise` that introduces noise to the data. This function will take a `PlaceHolder` object as input and return a noisy `PlaceHolder` object. As we are working with unattributed graphs, we will only apply noise to the edges."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZyKhSOII-ed"
      },
      "source": [
        "**2.3.1. [5 points]** **Complete the implementation** of the `corrupt_edges` function. You should\n",
        "- Compute the corrupted edge probability distribution with `Qtb`(need to be computed by yourself) and `E`;\n",
        "- Sample the noisy edges `E_t` from the corrupted multinomial distribution. Remember that the noisy edges `E_t` to return should be symmetrical and in one-hot encoding form, as they are realizations and not distributions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw0-MsvSI-ed"
      },
      "outputs": [],
      "source": [
        "def corrupt_edges(E: torch.Tensor, t_int: torch.Tensor, noise_dist: torch.Tensor, node_mask: torch.Tensor):\n",
        "    bs = E.size(0)\n",
        "    n = E.size(1)  # number of nodes\n",
        "    de = len(noise_dist)  # number of edge classes, i.e., 2\n",
        "\n",
        "    idx = t_int.to('cpu').squeeze(-1)\n",
        "\n",
        "    # Compute the corrupted edge probability distribution with `Qtb` and `E`\n",
        "    # Your solution here ###########################################################\n",
        "    probE = ...\n",
        "    #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "    # masked edges should also have a valid distribution instead of having all 0s.\n",
        "    inverse_edge_mask = ~(node_mask.unsqueeze(1) * node_mask.unsqueeze(2))\n",
        "    diag_mask = torch.eye(n).unsqueeze(0).expand(bs, -1, -1)\n",
        "    probE[inverse_edge_mask] = 1 / probE.shape[-1]\n",
        "    probE[diag_mask.bool()] = 1 / probE.shape[-1]\n",
        "    probE = probE.reshape(bs * n * n, -1)    # (bs * n * n, de_out)\n",
        "\n",
        "    # Sample the noisy edges `E_t` with this corrupted multinomial distribution\n",
        "    # Your solution here ###########################################################\n",
        "    E_t = ...\n",
        "    #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "    return E_t\n",
        "\n",
        "def apply_noise(holder, T, noise_dist, node_mask):\n",
        "    # sample a random time step for each sample in the batch\n",
        "    t_int = torch.randint(1, T + 1, size=(holder.E.size(0), 1))\n",
        "    # apply noise to edges - the nodes remains unchanged as they have a single dimension\n",
        "    E = holder.E\n",
        "    E_t = corrupt_edges(E, t_int, noise_dist, node_mask)\n",
        "\n",
        "    # Outputs masked placeholder!\n",
        "    return PlaceHolder(X=holder.X, E=E_t, y=holder.y).mask(node_mask), t_int\n",
        "\n",
        "# example for test\n",
        "n = 2\n",
        "bs = 3\n",
        "E = torch.Tensor([[0,1],[1,0]]).repeat(bs, 1, 1).long()\n",
        "E = torch.nn.functional.one_hot(E, 2).float()\n",
        "holder = PlaceHolder(X=torch.ones(bs, n, 1), E=E, y=None)\n",
        "noise_dist = torch.Tensor([0.5, 0.5])\n",
        "node_mask = torch.ones(bs, n).bool()\n",
        "\n",
        "apply_noise(holder, 1000, noise_dist, node_mask)[0].E[1,:,:,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQiL-YKPI-ee"
      },
      "source": [
        "### Question 2.4 - Model Implementation [6 points]\n",
        "\n",
        "In this part, we will begin the deep learning phase by designing a GNN model architecture.\n",
        "\n",
        "In this project, a graph $G$ is represented by node features $X$ of size $(n, 1)$ and edge features $E$ of size $(n, n, 2)$. We will employ a graph transformer to model the interactions among nodes. This approach enables the integration of quadratic edge features into the attention layer, enhancing the model's ability to capture complex relationships within the graph.\n",
        "\n",
        "More precisely, the model will take a PlaceHolder as input and return a PlaceHolder as output. The input PlaceHolder should contain $X$, $E$, and the graph feature $y$, where $y$ includes at least the time information $t$ of the diffusion process (where $t \\in [0, 1000]$ and $T=1,000$). $G_0$ refers to a clean graph, while $G_t$ refers to a noised graph at step $t$. The output PlaceHolder should contain the predicted distribution (probabilities) over the clean graph $\\hat{E}_0$ (X can be ignored as we set them to be 1 at all steps) given a noised graph.\n",
        "\n",
        "But, dealing with the dense tensors of size $[bs, n, n, 2]$ could be challenging for implementing given the requirement of frequent masking. So, in this section, we start by an easier model and leverage a sparse graph representation supported directly by `pytorch geometric`. This model should be composed of a GNN trunk (whose architecture you can choose freely) to extract node features from the input graph, and some MLP layers for link prediction (in this case, prediction of probabilities for edge classes). More precisely:\n",
        "- The GNN trunk should takes node features and edge index as input (several `pytorch geometric` models are readily available, fell free to use them), and output node features;\n",
        "- Build input features for the MLP layers  from the previous node features. Note that the input features to the MLP for the prediction of $e_{i,j}$ should be invariant to the order of the nodes, i.e.,\n",
        "for the edge prediction module `m` we should have a good `m(x_i, x_j)=m(x_j, x_i)\n",
        "- These node ordering invariant edge features should be passed to the MLP layers for edge classification (probabilities prediction over edge classes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9BUIsaKI-ee"
      },
      "source": [
        "**2.4.1. [6 points]** **Complete the simple model** architecture given in the following block.\n",
        "<!-- - Define your own gnn network, and obtain node_embedding with it.\n",
        "- After this, you need to perform the link prediction between all node pairs with your own link prediction module $l$, remember that $l(e_1, e_2)=l(e_2, e_1)$.\n",
        "- Remember that the number of nodes for different graphs are different, so that you may need to add some masks for link prediction.\n",
        "- The block should output `output_E` which is of size $(bs, n, n, 2)$. -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpoQ5TQLI-ee"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch_geometric.nn.models import MLP, GIN, GAT\n",
        "from torch_geometric.data import Batch, Data\n",
        "from torch_geometric.utils import dense_to_sparse\n",
        "from itertools import combinations\n",
        "\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dims: int,\n",
        "                 num_GNN_layers: int,\n",
        "                 hidden_dims: int,\n",
        "                 num_MLP_layers: int,\n",
        "                 hidden_MLP_dims: int,\n",
        "                 output_dims: int):\n",
        "        super().__init__()\n",
        "        # Your solution here ###########################################################\n",
        "        self.gnn = ...\n",
        "        self.mlp = ...\n",
        "        #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "    def forward(self, holder: PlaceHolder, node_mask: torch.Tensor) -> PlaceHolder:\n",
        "        max_n_nodes = holder.E.shape[1]\n",
        "        # convert holder to data\n",
        "        data = holder_to_data_batch(holder, node_mask)\n",
        "\n",
        "        # add timestep concatenating in node features\n",
        "        time = data.y\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        time_as_x = time[data.batch].unsqueeze(-1)\n",
        "        x = torch.hstack((x.unsqueeze(-1), time_as_x))\n",
        "\n",
        "        # Your solution here ###########################################################\n",
        "        node_embeddings = ...\n",
        "        output_E = ...\n",
        "        #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "        output_holder = PlaceHolder(X=holder.X, E=output_E, y=None).mask(node_mask)\n",
        "\n",
        "        return output_holder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfswR9BTBajr"
      },
      "outputs": [],
      "source": [
        "def collapse_placeholder(holder):\n",
        "    E = torch.argmax(holder.E, dim=-1)\n",
        "    return PlaceHolder(X=holder.X, E=E, y=holder.y)\n",
        "\n",
        "def holder_to_data_batch(holder, node_mask):\n",
        "    # WARNING: holder should already be masked!\n",
        "    data_list = []\n",
        "    holder = collapse_placeholder(holder)\n",
        "\n",
        "    for graph_idx in range(holder.X.size(0)):\n",
        "        this_node_mask = node_mask[graph_idx]\n",
        "        n_nodes = this_node_mask.sum()\n",
        "        X = holder.X[graph_idx].squeeze()\n",
        "        X = X[this_node_mask]\n",
        "        E = holder.E[graph_idx]\n",
        "        edge_index, edge_attr = dense_to_sparse(adj=E[:n_nodes, :n_nodes])\n",
        "        y = holder.y[graph_idx]\n",
        "        data = Data(x=X, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "        data.validate(raise_on_error=True)\n",
        "        data_list.append(data)\n",
        "\n",
        "    data_batch = Batch.from_data_list(data_list)\n",
        "\n",
        "    return data_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90x9mTH9I-ee"
      },
      "source": [
        "Please use the following block to check if your implementation is correct.\n",
        "\n",
        "An example of a valid output would be:\n",
        "\n",
        "```\n",
        "output X is represented by tensor([1.])\n",
        "output E is represented by tensor([ 0.4379, -0.4380])\n",
        "```\n",
        "\n",
        "Note that the model should output logits for each edge and not actual probabilities, i.e., the output does not need to sum to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEoLeOkgI-ee"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Check the validity of the model architecture with an simple example\n",
        "args_simple = {'num_MLP_layers': 4,\n",
        "        'num_GNN_layers': 4,\n",
        "        'input_dims': 1,\n",
        "        'hidden_dims': 256,\n",
        "        'hidden_MLP_dims': 256,\n",
        "        'output_dims': 2}\n",
        "model_example = SimpleModel(**args_simple)\n",
        "\n",
        "bs = 32\n",
        "n = 5\n",
        "X = torch.ones((bs, n, 1))\n",
        "E = torch.randn((bs, n, n, 2))\n",
        "y = torch.randint(0, 10, (bs, 1))/10\n",
        "node_mask = torch.Tensor([[1, 1, 1, 1, 0]]).repeat(bs, 1).bool()\n",
        "\n",
        "with torch.no_grad():\n",
        "        res = model_example(PlaceHolder(X=X, E=E, y=y), node_mask)\n",
        "print('output X is represented by', res.X[0,0])\n",
        "print('output E is represented by', res.E[0,0,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c54rtoy9I-ee"
      },
      "source": [
        "### Question 2.5 - Model training [6 points]\n",
        "\n",
        "Now we can proceed with the training procedure for our diffusion model. Essentially, our model $f_\\theta$ is trained to predict the clean data distribution $\\hat{G}_0$ given a corrupted graph $G_t$. We will use the cross-entropy loss for edges, summed up for backpropagation.\n",
        "\n",
        "In the following question, let's write the training process!\n",
        "\n",
        "<!-- To achieve this, we will begin by creating a dataloader using the provided code. Each data point of type networkx.graph will be converted to a data object supported by PyTorch Geometric. While the conversion process details may not be essential here, understanding the `Data` type could be beneficial in other graph-related projects. In the following part, we provide some available codes for:\n",
        "1. Compare the results on training/validation dataset of ER model and diffusion model;\n",
        "2. Convert sparse data to dense ones. -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHukhBfxI-ee"
      },
      "source": [
        "**2.5.1. [3 points]** **Complete the training process**. In this step, you need to predict the clean graph distribution, then perform the cross-entropy loss calculation and backpropagation. The `eigen_feats` will be used in the last part, and can be ignored here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghF38aqDI-ee"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def seed_torch(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if using multiple GPUs\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "def train_model(model, train_dataloader, val_dataloader, n_epochs, noise_dist, T, eigen_feats):\n",
        "    # Training parameters\n",
        "    seed_torch(0)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
        "\n",
        "    val_loss_list = []\n",
        "    loss_list = []\n",
        "    val_metric = torch.nn.CrossEntropyLoss()\n",
        "    train_loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Iterate over the batches\n",
        "    for epoch_idx in tqdm(range(n_epochs)):\n",
        "        model.train()\n",
        "        epoch_loss = []\n",
        "        for batch in train_dataloader:\n",
        "\n",
        "            # Access the batch data\n",
        "            unmasked_holder, node_mask = to_dense(batch)\n",
        "            noise_holder, t_int = apply_noise(unmasked_holder, T, noise_dist, node_mask)\n",
        "            target_holder = unmasked_holder.mask(node_mask)\n",
        "\n",
        "            # Prepare data for inference\n",
        "            noise_holder.y = t_int.float() / T\n",
        "            noise_holder = noise_holder.to(device)\n",
        "            node_mask = node_mask.to(device)\n",
        "            target_holder = target_holder.to(device)\n",
        "\n",
        "            if eigen_feats is not None:\n",
        "                add_feats = eigen_feats(noise_holder.E, node_mask)\n",
        "                noise_holder.X = torch.cat((noise_holder.X, add_feats[2], add_feats[3]), -1)\n",
        "                noise_holder.y = torch.cat((noise_holder.y, add_feats[0], add_feats[1]), -1)\n",
        "\n",
        "            # Your solution here ###########################################################\n",
        "            loss = ...\n",
        "            #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "            loss = loss.detach().cpu().item()\n",
        "            epoch_loss.append(loss)\n",
        "\n",
        "        loss_list.append(np.mean(epoch_loss))\n",
        "        val_loss = validation_step(val_dataloader, val_metric, model, noise_dist, T, eigen_feats)\n",
        "        val_loss_list.append(val_loss)\n",
        "\n",
        "    # Baseline\n",
        "    er_train_loss = er_validation_step(train_dataloader,val_metric, er_model)\n",
        "    er_train_loss_arr = er_train_loss * np.ones(n_epochs)\n",
        "    er_val_loss = er_validation_step(val_dataloader,val_metric, er_model)\n",
        "    er_val_loss_arr = er_val_loss * np.ones(n_epochs)\n",
        "    print(epoch_loss[-1])\n",
        "\n",
        "    plt.plot(loss_list, label=\"train_loss\")\n",
        "    window_size = 10\n",
        "    plt.plot(np.convolve(loss_list, np.ones(window_size)/window_size, mode='valid'), label=\"smooth train\")\n",
        "    plt.plot(val_loss_list, label=\"val_loss\")\n",
        "    plt.plot(er_train_loss_arr, label=\"er_train_loss\")\n",
        "    plt.plot(er_val_loss_arr, label=\"er_val_loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def validation_step(val_dataloader, val_metric, model, noise_dist, T, eigen_feats):\n",
        "    model.eval()\n",
        "\n",
        "    # Get val loss\n",
        "    loss_list = []\n",
        "    for batch in val_dataloader:\n",
        "        # Access the batch data\n",
        "        unmasked_holder, node_mask = to_dense(batch)\n",
        "        noise_holder, t_int = apply_noise(unmasked_holder, T, noise_dist, node_mask)\n",
        "        target_holder = unmasked_holder.mask(node_mask)\n",
        "\n",
        "        # Prepare data for inference\n",
        "        noise_holder.y = t_int.float() / T\n",
        "        noise_holder = noise_holder.to(device)\n",
        "        node_mask = node_mask.to(device)\n",
        "        target_holder = target_holder.to(device)\n",
        "\n",
        "        # get values for training model\n",
        "        with torch.no_grad():\n",
        "            if eigen_feats is not None:\n",
        "                add_feats = eigen_feats(noise_holder.E, node_mask)\n",
        "                noise_holder.X = torch.cat((noise_holder.X, add_feats[2], add_feats[3]), -1)\n",
        "                noise_holder.y = torch.cat((noise_holder.y, add_feats[0], add_feats[1]), -1)\n",
        "\n",
        "            pred = model(noise_holder, node_mask)\n",
        "            E_true = target_holder.E.reshape(-1, target_holder.E.shape[-1])\n",
        "            E_pred = pred.E.reshape(-1, pred.E.shape[-1])\n",
        "            loss = val_metric(E_pred, E_true)\n",
        "        loss_list.append(loss.detach().cpu().numpy())\n",
        "\n",
        "    val_loss = sum(loss_list)/len(loss_list)\n",
        "\n",
        "    return val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA6HFQhqI-ee"
      },
      "source": [
        "**2.5.2. [3 points]** **Define your own hyperparameters** and use the `train_model` function to **train your model**. **Comment on your training curve.**\n",
        "\n",
        "**Remark**: we will assign maximum grade in this question to any model implementation whose validation loss is below the expected validation loss for the ER model (which will be shown in the figure when you run the function `train_model`). Please do not spend too much time over optimizing your model beyond that baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vfvs7uD8I-ee"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "bs = 32\n",
        "train_dataloader = utils.nx_list_to_dataloader(nx_dataset[\"train\"], bs=bs)\n",
        "val_dataloader = utils.nx_list_to_dataloader(nx_dataset[\"val\"], bs=bs)\n",
        "test_dataloader = utils.nx_list_to_dataloader(nx_dataset[\"test\"], bs=bs)\n",
        "n_epochs = 500 # you can try epoches if you want\n",
        "\n",
        "# Your solution here ###########################################################\n",
        "\n",
        "simple_model = ...\n",
        "\n",
        "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Your answer here:**\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNT6TBLrI-ee"
      },
      "source": [
        "### Question 2.6 - Generation (Reverse Process) [2 points]\n",
        "\n",
        "With the trained model, we can now generate new graphs from uniform noise!\n",
        "\n",
        "As discussed in D3PM (*Austin* et al., D3PM, 2021) and DiGress, for discrete data $X$, the generation is done step by step from $t=T$ to $t=1$.\n",
        "\n",
        "Intuitively, the procedure is as follows:\n",
        "- first, use the trained model $f_\\theta$ to predict a distribution over $x_0$.\n",
        "- noise the previously obtained distribution for $x_0$ back $x_{t-1}$ using the posterior of the forward process, given by:\n",
        "\n",
        "$$\n",
        "q(x_{t-1}|x_t,x_0)=\\frac{q(x_t|x_{t-1}, x_0)q(x_{t-1}|x_0)}{q(x_t|x_0)} = Cat(x_{t-1};p=\\frac{x_tQ_t^\\top\\odot x_0\\bar{Q}_{t-1}}{x_0\\bar{Q}_tx_t^\\top})\n",
        "$$\n",
        "\n",
        "- sample a graph from the distribution over $x_{t-1}$\n",
        "\n",
        "This step by step denoising is crucial for the success of diffusion models as it allows to deconstruct the complex task of mapping two distributions into smaller subproblems.\n",
        "\n",
        "If some of these descriptions sounded a bit confusing, do not worry, we provide the (almost) complete code for it. You only have to care about the sampling of the number of nodes - as simple as for the ER model! Nevertheless, if you are interested, you are free to check its full implementation below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLkuFnEuI-ee"
      },
      "source": [
        "**2.6.1. [2 points]** **Sample the number of nodes** (`n_nodes`) for the graph to be generated, and **retrieve the node mask** (`node_mask`) with it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bjb3Jeh9I-ee"
      },
      "outputs": [],
      "source": [
        "def sample_graph(model, noise_dist, T, n_graphs, num_timesteps_to_save=5, eigen_feats=None):\n",
        "    seed_torch(0)\n",
        "    max_n_nodes = len(n_nodes_dist) - 1\n",
        "    de = len(noise_dist)\n",
        "\n",
        "    # Your solution here ###########################################################\n",
        "    # sample the number of nodes for n_graphs\n",
        "    n_nodes = ...\n",
        "    node_mask = ...\n",
        "    #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "    # sample a purely noised graph at step T\n",
        "    limit_dist = noise_dist.repeat(n_graphs * max_n_nodes * max_n_nodes, 1)\n",
        "    limit_E = limit_dist.multinomial(1, replacement=True)\n",
        "    limit_E = limit_E.reshape(n_graphs, max_n_nodes, max_n_nodes)\n",
        "    limit_E = torch.nn.functional.one_hot(limit_E, 2).float()\n",
        "    limit_E = utils.symmetrize(limit_E)\n",
        "\n",
        "    holder = PlaceHolder(X=torch.ones(n_graphs, max_n_nodes, 1),\n",
        "                         E=limit_E,\n",
        "                         y=torch.Tensor([1]).unsqueeze(-1).repeat(n_graphs, 1),).to(device).mask(node_mask)\n",
        "\n",
        "    saving_steps = torch.linspace(0, T, num_timesteps_to_save).round()\n",
        "    saved_holders = [holder.to('cpu')]  # save initial holder\n",
        "    print(\"Saving timesteps: \", saving_steps)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for t in tqdm(range(1, T+1)[::-1]):\n",
        "            steps = torch.Tensor([t]).unsqueeze(-1).repeat(n_graphs, 1).to(device)\n",
        "            steps_next = steps - 1\n",
        "            holder.y = steps / T\n",
        "\n",
        "            if eigen_feats is not None:\n",
        "                add_feats = eigen_feats(holder.E, node_mask)\n",
        "                holder.X = torch.cat((holder.X, add_feats[2], add_feats[3]), -1)\n",
        "                holder.y = torch.cat((holder.y, add_feats[0], add_feats[1]), -1)\n",
        "\n",
        "            pred_G0 = model(holder, node_mask)\n",
        "            pred_E = torch.softmax(pred_G0.E, dim=-1)\n",
        "            shape_E = pred_E.shape\n",
        "            E_t = holder.E.to(torch.float32)              # bs, n, n, 2\n",
        "\n",
        "            # transition matrix used in the reverse process of size (bs, 2, 2)\n",
        "            Qtb = get_Q_t_bar(all_alphas_bar[steps[:, 0].long().to('cpu')], noise_dist, e_class=2).to(device)\n",
        "            Qsb = get_Q_t_bar(all_alphas_bar[steps_next[:, 0].long().to('cpu')], noise_dist, e_class=2).to(device)\n",
        "            Qt = get_Q_t(all_betas[steps[:, 0].long().to('cpu')], noise_dist, e_class=2).to(device)\n",
        "\n",
        "            # posterior computation\n",
        "            E_t = E_t.flatten(start_dim=1, end_dim=-2).to(torch.float32)            # bs x N x dt\n",
        "\n",
        "            Qt_T = Qt.transpose(-1, -2)                 # bs, dt, d_t-1\n",
        "            left_term = E_t @ Qt_T                      # bs, N, d_t-1\n",
        "            left_term = left_term.unsqueeze(dim=2)      # bs, N, 1, d_t-1\n",
        "\n",
        "            right_term = Qsb.unsqueeze(1)               # bs, 1, d0, d_t-1\n",
        "            numerator = left_term * right_term          # bs, N, d0, d_t-1\n",
        "\n",
        "            X_t_transposed = E_t.transpose(-1, -2)      # bs, dt, N\n",
        "\n",
        "            prod = Qtb @ X_t_transposed                 # bs, d0, N\n",
        "            prod = prod.transpose(-1, -2)               # bs, N, d0\n",
        "            denominator = prod.unsqueeze(-1)            # bs, N, d0, 1\n",
        "            denominator[denominator == 0] = 1e-6\n",
        "\n",
        "            p_s_and_t_given_0_E = numerator / denominator\n",
        "\n",
        "            # noise back\n",
        "            pred_E = pred_E.reshape((n_graphs, -1, pred_E.shape[-1]))\n",
        "            weighted_E = pred_E.unsqueeze(-1) * p_s_and_t_given_0_E        # bs, N, d0, d_t-1\n",
        "            unnormalized_prob_E = weighted_E.sum(dim=-2)\n",
        "            unnormalized_prob_E[torch.sum(unnormalized_prob_E, dim=-1) == 0] = 1e-5\n",
        "            prob_E = unnormalized_prob_E / torch.sum(unnormalized_prob_E, dim=-1, keepdim=True)\n",
        "            prob_E = prob_E.reshape(n_graphs, max_n_nodes, max_n_nodes, pred_E.shape[-1])\n",
        "\n",
        "            # sample at timestep t-1\n",
        "            E_s = prob_E.reshape(-1, de).multinomial(1, replacement=True)\n",
        "            E_s = torch.nn.functional.one_hot(E_s, 2).float().reshape(shape_E)\n",
        "            E_s = utils.symmetrize(E_s)\n",
        "\n",
        "            assert (E_s == torch.transpose(E_s, 1, 2)).all()\n",
        "            assert (E_s.shape == E_s.shape)\n",
        "\n",
        "            holder = PlaceHolder(X=torch.ones(n_graphs, max_n_nodes, 1).to(device),\n",
        "                                E=E_s, y=steps_next/T).to(device).mask(node_mask)\n",
        "\n",
        "            # Save graphs\n",
        "            if t-1 in saving_steps:\n",
        "                saved_holders.append(holder.to('cpu'))\n",
        "\n",
        "    return holder, saved_holders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivdYoWkHI-ef"
      },
      "source": [
        "The following block enables you to sample new graphs with the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7I5GE_QI-ef"
      },
      "outputs": [],
      "source": [
        "num_graphs_to_generate = len(nx_dataset[\"test\"])\n",
        "\n",
        "simple_model_graphs, simple_model_intermediate_graphs = sample_graph(simple_model, noise_dist, T, num_graphs_to_generate, num_timesteps_to_save=5, eigen_feats=None)\n",
        "\n",
        "graphs_to_eval[\"simple\"] = simple_model_graphs.to_nx_graph_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2_R7WpUI-ef"
      },
      "source": [
        "# **Part 3: Evaluation and Comparison [15 pts]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E51bLuH9I-ef"
      },
      "source": [
        "\n",
        "### Question 3.1 - Visualization [2 points]\n",
        "We will visualize the denoising process of the diffusion model. While the diffusion process is expected to gradually corrupt the graph towards the prescribed limit distribution, in the denoising process one should expect the reverse. We will visualize 2 graphs (one per row) at different steps of the diffusion process using the provided function `plot_intermediate_graphs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JclbUmIfI-ef"
      },
      "outputs": [],
      "source": [
        "utils.plot_intermediate_graphs(simple_model_intermediate_graphs, T, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoktlQydI-ef"
      },
      "source": [
        "**3.1.1. [2 points]** **Comment briefly.** What do you observe? Are the final graphs similar to what you expected? What can you conclude from the visualization?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz3T8f3WI-ef"
      },
      "source": [
        "\n",
        "**Your answer here:**\n",
        "\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIDjV7y3I-ef"
      },
      "source": [
        "\n",
        "### Question 3.2: Quantitative Comparison [5 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAfFaGepI-ef"
      },
      "source": [
        "As noticed in Part 1, evaluating graph generation just based on visual inspection is not enough. We need to compare the generated graphs quantitatively. One common approach in graph generation is to compare populations of graph-wise statistics. In this case, we will consider two different statistics:\n",
        "- The degree distribution of the nodes.\n",
        "- The clustering coefficient of the nodes.\n",
        "\n",
        "For each graph, we will get a distribution (in practice, an histogram) of nodes degrees and a distribution (similarly, an histogram) of node clustering coefficients. Consequently for a graph dataset, we will get a set of histograms for each statistic. Therefore, we can compare how similar two datasets are in terms of the chosen statistic by comparing the two sets of histograms through some notion of \"distance\" between distributions. The more similar the two sets of histograms are, the more similar the two datasets are (at least, in terms of that statistic), so smaller should be the distance between them. In graph generation, it is usual to use the Maximum Mean Discrepancy (MMD) as such notion of \"distance\". You do not have to worry too much about it, just know that it is a measure of the similarity of distributions.\n",
        "\n",
        "Finally, since such notion of \"distance\" is not easily interpretable, we consider as a final result the following ratio (with some abuse of notation):\n",
        "\n",
        "$$\n",
        "\\frac{\\operatorname{MMD} \\, (\\text{generated}, \\text{test})}{\\operatorname{MMD} \\, (\\text{train}, \\text{test})},\n",
        "$$\n",
        "\n",
        "where generated, train, and test consist of the histograms of a statistic for the generated graphs, the training graphs, and the test graphs, respectively. This ratio will be our final evaluation metric, since in principle, the best MMD we could hope for is the one between the training and test datasets, as the training dataset is the one we are trying to approximate. Therefore, the expected optimal (minimum) value is 1.\n",
        "\n",
        "<!-- In graph generation, it is usual to use the [Maximum Mean Discrepancy](https://jmlr.csail.mit.edu/papers/v13/gretton12a.html) (MMD) as such notion of \"distance\". You do not have to worry too much about it, just know that it is a measure of the similarity of distributions.\n",
        "\n",
        "To make you more familiar, an alternative to MMD could be the widely know Kullback-Leibler divergence (it suffers from some limitations, such as the assymetry in its inputs, sensitivity to zero probabilities, etc). In any case, we provide you an implementation of the MMD function.\n",
        "\n",
        "Finally, since such notion of \"distance\" is not easily interpretable, we consider as a final result the following ratio (with some abuse of notation):\n",
        "\n",
        "$$\n",
        "\\frac{\\operatorname{MMD} \\, (\\text{generated}, \\text{test})}{\\operatorname{MMD} \\, (\\text{train}, \\text{test})},\n",
        "$$\n",
        "\n",
        "where generated, train, and test consist of the histograms of a statistic for the generated graphs, the training graphs, and the test graphs, respectively. This ratio will be our final evaluation metric, since in principle, the best MMD we could hope for is the one between the training and test datasets, as the training dataset is the one we are trying to approximate. Therefore, the expected optimal (minimum) value is 1. -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBb2l5k7I-ef"
      },
      "source": [
        "\n",
        "**3.2.1. [4 points]** **Implement the functions** `...hist_array`.\n",
        "You can use functions from *networkx* (e.g., `nx.degree_histogram`, `nx.clustering`, and `nx.histogram`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKIckaIaI-ef"
      },
      "outputs": [],
      "source": [
        "def get_degree_hist_array(nx_dataset: List[nx.Graph], max_degree: int =20) -> np.ndarray:\n",
        "    \"\"\"The output should be an np.array of shape (len(nx_dataset), max_degree),  where each row corresponds to the degree histogram obtained for a different graph of the dataset.\"\"\"\n",
        "    deg_hist_array = np.zeros((len(nx_dataset), max_degree))\n",
        "    # Your solution here ###########################################################\n",
        "\n",
        "    #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "    return deg_hist_array\n",
        "\n",
        "def get_clustering_hist_array(nx_dataset, num_bins=10) -> np.ndarray:\n",
        "    \"\"\"The output should be an np.array of shape (len(nx_dataset), num_bins), where each row corresponds to the node cluster coefficient histogram obtained for a different graph of the dataset.\"\"\"\n",
        "    clustering_hist_array = np.zeros((len(nx_dataset), num_bins))\n",
        "    # Your solution here ###########################################################\n",
        "\n",
        "    #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "    return clustering_hist_array\n",
        "\n",
        "dict_stat_fn = {\n",
        "    \"degree\": get_degree_hist_array,\n",
        "    \"clustering\": get_clustering_hist_array,\n",
        "}\n",
        "final_results = utils.QuantitativeResults(dict_stat_fn=dict_stat_fn, train_dataset=nx_dataset[\"train\"][:20], test_dataset=nx_dataset[\"test\"])\n",
        "for gen_method, gen_dist in graphs_to_eval.items():\n",
        "    final_results.add_results(gen_method, gen_dist)\n",
        "final_results.show_table()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IFR1_hjI6FI"
      },
      "source": [
        "**3.2.2. [1 point]** Comment briefly on this quantitative result.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF_qAICCJAHj"
      },
      "source": [
        "\n",
        "**Your answer here:**\n",
        "\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy-ZhQJ0I-ef"
      },
      "source": [
        "### Question 3.3: Improving Results [8 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD_nfy4hI-ef"
      },
      "source": [
        "In this section, we will implement a more sophisticated architecture, `GraphTransformer`, provided in `transformer_model.py`. This new architecture enhances interactions through:\n",
        "\n",
        "- Modules that effectively integrate node, edge, and graph-level features;\n",
        "- A refined masking mechanism that allows operations on dense tensors instead of relying solely on edge lists.\n",
        "\n",
        "Your task is to readily utilize this architecture, and compare its performance with the simpler model previously discussed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfPSt9xLI-ef"
      },
      "source": [
        "**3.3.1. [4 points]** Using the **model provided**, **retrain**, **resample**, **replot** and **re-evaluate**. **Comment** briefly on your observations.\n",
        "\n",
        "Remark: You may observe a lot of fluctuations on the curve, it's normal so do not worry about that. Look at the `smooth_train` in this case could be helpful. Please refer to what we did in the previous model to show your results :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IWwEkhvI-ef"
      },
      "outputs": [],
      "source": [
        "from transformer_model import GraphTransformer\n",
        "\n",
        "# Some hyper-parameters by default you can use - of course you can change them if you want !\n",
        "\n",
        "args_gt = {'n_layers': 4,\n",
        "        'n_head': 8,\n",
        "        'input_dims': {'X': 1, 'E': 2, 'y': 1},\n",
        "        'hidden_dims': {'X': 256, 'E': 256, 'y': 256, 'dx': 64, 'de': 64, 'dy': 64},\n",
        "        'output_dims': {'X': 1, 'E': 2, 'y': 1},}\n",
        "n_epochs = 500\n",
        "\n",
        "\n",
        "# Your solution here ###########################################################\n",
        "\n",
        "# Train\n",
        "\n",
        "# Generate\n",
        "\n",
        "# Visualize and evaluate\n",
        "\n",
        "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhGnaPZlI-ef"
      },
      "source": [
        "**Your answer here:**\n",
        "\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjd1DS-xI-ef"
      },
      "source": [
        "Even with such an expressive architecture, the results are still not satisfactory!\n",
        "\n",
        "As introduced in the lectures, GNN's expressivity is limited. To further enhance the model expressivity, it is a common practice to provide the model some additional information. One of the most performing and most popular additional features is the eigenvalues and the eigenvectors of the Laplacian matrix. While the former can be passed as additional graph-level features, the latter can be passed as additional node-level features.\n",
        "\n",
        "At this point, we can now better motivate the use of the `PlaceHolder` class. Previously, the reason was not obvious since `X` and `y` did not contain much information. Contrarily, now we will pass the `eigen_feats` through them (you can re-check the `train_model` function implementation to better understand what is happening under the hood). The eigenvalues and eigenvectors of the Laplacian can be obtained from the `EigenFeatures` class, provided in `nml24_assignment3.py` (already imported in this ipynb as `utils`). Please initialize that class with the input `'all'`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6Aox4cEI-ef"
      },
      "source": [
        "**3.3.2. [4 points]** Similarly, **use the model and EigenFeatures class provided**, **retrain**, **resample**, **replot** and **re-evaluate**. **Comment** briefly on your observations. Do not remember to change the `input_dims` in `args_gt_pp` to run your codes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAYLZ-YXI-eg"
      },
      "outputs": [],
      "source": [
        "args_gt_pp = args_gt\n",
        "eigen_feats = utils.EigenFeatures('all')\n",
        "\n",
        "# Your solution here ###########################################################\n",
        "\n",
        "# Train\n",
        "\n",
        "# Generate\n",
        "\n",
        "# Visualize and evaluate\n",
        "\n",
        "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHlAjRaVI-eg"
      },
      "source": [
        "**Your answer here:**\n",
        "\n",
        "...\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
